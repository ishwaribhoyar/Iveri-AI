<div align="center">

# ğŸ¤– IVERI

### Voice-First AI Operating Layer for Edge Computing

[![Python](https://img.shields.io/badge/Python-3.8+-3776AB.svg?logo=python&logoColor=white)](https://python.org)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--5--nano-412991.svg?logo=openai&logoColor=white)](https://openai.com)
[![Raspberry Pi](https://img.shields.io/badge/Raspberry%20Pi-4-C51A4A.svg?logo=raspberrypi&logoColor=white)](https://raspberrypi.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Platform](https://img.shields.io/badge/Platform-Cross--Platform-blue.svg)]()

<br>

**IVERI** is a sophisticated voice-controlled AI operating layer that transforms traditional computing into a conversational experience. Built on a multi-layered cognitive architecture, it enables natural language system control on edge devices like Raspberry Pi.

<br>

[Architecture](#-technical-architecture) â€¢ [Features](#-feature-matrix) â€¢ [Installation](#-installation) â€¢ [Research](#-research-applications) â€¢ [API](#-api-reference)

</div>

---

## ğŸ¯ Overview

IVERI reimagines human-computer interaction by replacing traditional GUI-based computing with **natural language system control**. Unlike cloud-dependent assistants (Alexa, Google Assistant), IVERI runs on-device, controls local system resources, maintains persistent memory, and integrates with IoT hardware.

### Key Differentiators

| Aspect | Cloud Assistants | IVERI |
|--------|------------------|-------|
| **Processing** | Cloud-dependent | Edge computing (on-device) |
| **System Control** | Limited to web queries | Full OS control (apps, files, settings) |
| **Privacy** | Data sent to servers | Processed locally |
| **Hardware** | No GPIO access | Full IoT integration |
| **Memory** | Session-based | Persistent across reboots |
| **Customization** | Closed ecosystem | Fully open-source |
| **Cost** | Subscription required | Free (open-source) |

---

## ğŸ—ï¸ Technical Architecture

IVERI implements a **multi-layered cognitive architecture** optimized for edge deployment:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    IVERI AI Operating Layer                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Layer 4: Speech Synthesis                       â”‚   â”‚
â”‚  â”‚  â€¢ Text-to-Speech Engine (pyttsx3)                          â”‚   â”‚
â”‚  â”‚  â€¢ Prosody Control & Voice Selection                         â”‚   â”‚
â”‚  â”‚  â€¢ Interruptible Output Stream                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â–²                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Layer 3: System Abstraction                     â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚ Process  â”‚  â”‚  File    â”‚  â”‚  GPIO    â”‚  â”‚ Network  â”‚    â”‚   â”‚
â”‚  â”‚  â”‚ Control  â”‚  â”‚  System  â”‚  â”‚ Hardware â”‚  â”‚  Stack   â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â–²                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Layer 2: Natural Language Understanding              â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚   â”‚
â”‚  â”‚  â”‚  Intent Classifier â”‚    â”‚   GPT-5-nano LLM   â”‚           â”‚   â”‚
â”‚  â”‚  â”‚  (Rule-based, 59   â”‚ OR â”‚  (Transformer,     â”‚           â”‚   â”‚
â”‚  â”‚  â”‚   command patterns)â”‚    â”‚   128k context)    â”‚           â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚   â”‚
â”‚  â”‚              â–²                      â–²                        â”‚   â”‚
â”‚  â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚   â”‚
â”‚  â”‚                         â”‚                                    â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚  â”‚           Context Manager & Memory Store            â”‚     â”‚   â”‚
â”‚  â”‚  â”‚         (Sliding window + Persistent JSON)          â”‚     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â–²                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚            Layer 1: Acoustic Processing Pipeline             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚  Audio   â”‚  â”‚  Wake    â”‚  â”‚  Voice   â”‚  â”‚ Speech-  â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  Capture â”‚â”€â–¶â”‚  Word    â”‚â”€â–¶â”‚ Activity â”‚â”€â–¶â”‚ to-Text  â”‚    â”‚   â”‚
â”‚  â”‚  â”‚ (PyAudio)â”‚  â”‚(Porcupineâ”‚  â”‚Detection â”‚  â”‚ (Google) â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â”‚                    â”‚                                         â”‚   â”‚
â”‚  â”‚            On-device CNN                                     â”‚   â”‚
â”‚  â”‚            <1ms latency                                      â”‚   â”‚
â”‚  â”‚            0.1% CPU usage                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Hardware Layer                            â”‚   â”‚
â”‚  â”‚        Raspberry Pi 4 | USB Audio | GPIO | Bluetooth         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Layer Specifications

| Layer | Component | Technology | Performance |
|-------|-----------|------------|-------------|
| **L1: Acoustic** | Wake Word | Porcupine CNN | <1ms, offline |
| | Speech-to-Text | Google STT API | 95%+ accuracy |
| **L2: NLU** | Intent Classifier | Rule-based patterns | 59 commands |
| | Fallback LLM | GPT-5-nano | 128k context |
| | Memory Store | JSON persistence | Survives reboots |
| **L3: System** | Process Control | OS subprocess API | Cross-platform |
| | File System | Python os/pathlib | Full access |
| | GPIO | RPi.GPIO library | 40 pins |
| **L4: Synthesis** | TTS Engine | pyttsx3 | Real-time |

---

## ğŸ“Š Feature Matrix

### 59+ Voice Commands Across 14 Categories

<table>
<tr>
<td width="50%" valign="top">

#### ğŸŒ Web Automation (12)
- Open YouTube, Google, Facebook, Twitter
- Open GitHub, Instagram, LinkedIn, Reddit
- Open WhatsApp, Gmail, Spotify, Netflix

#### ğŸ” Intelligent Search (4)
- Google Search with query extraction
- YouTube Search with video intent
- Wikipedia direct article lookup
- Natural language search parsing

#### ğŸ’» Application Control (5)
- Calculator, Notepad, Terminal
- File Manager, System Settings
- Cross-platform app launching

#### ğŸ“‚ File System Navigation (3)
- Downloads, Documents, Desktop
- Dynamic path resolution
- OS-agnostic implementation

#### â° Temporal Queries (3)
- Current time with formatting
- Today's date with day name
- Contextual time responses

#### ğŸ“¸ Display Control (2)
- Screenshot capture to file
- Screen lock command

#### ğŸ”Š Audio Management (4)
- Volume up/down control
- Mute/unmute toggle
- System audio integration

</td>
<td width="50%" valign="top">

#### ğŸ’» System Information (3)
- Local IP address retrieval
- Battery status & charging state
- CPU temperature (Pi)

#### ğŸ§  Persistent Memory (4)
- Key-value pair storage
- Natural language recall
- Forget/delete capability
- Memory enumeration

#### ğŸ“ Notes System (3)
- Add notes with timestamps
- List all notes
- Clear notes database

#### ğŸŒ¤ï¸ Weather Integration (1)
- Real-time weather data
- City-based queries
- Temperature, humidity, conditions

#### ğŸ“° News Aggregation (5)
- General headlines
- Tech, Sports, Business, Entertainment
- Configurable sources

#### ğŸ’¡ IoT Hardware Control (4)
- LED on/off/toggle
- LED blink patterns
- GPIO abstraction layer
- Extensible for sensors

#### ğŸ’¬ Conversation Management (3)
- Help command listing
- History clearing
- Exit/goodbye handling

</td>
</tr>
</table>

---

## âš¡ Performance Metrics

| Metric | Value | Notes |
|--------|-------|-------|
| **End-to-end Latency** | ~500ms | Speech â†’ Response |
| **Wake Word Detection** | <1ms | On-device CNN |
| **CPU Usage (Idle)** | 0.1% | Wake word listening |
| **CPU Usage (Active)** | 5-10% | During processing |
| **Memory Footprint** | ~50MB | Python runtime |
| **STT Accuracy** | 95%+ | English, quiet environment |
| **Command Recognition** | 98%+ | For trained patterns |

---

## ğŸš€ Installation

### Prerequisites
- Python 3.8+
- Microphone & Speaker
- API Keys (OpenAI required)

### Windows (Development)

```bash
git clone https://github.com/Nishant-aiml/Iveri-AI-.git
cd Iveri-AI-
pip install -r requirements.txt
copy .env.example .env   # Configure API keys
python main.py
```

### Raspberry Pi (Production - One Command)

```bash
git clone https://github.com/Nishant-aiml/Iveri-AI-.git
cd Iveri-AI-
chmod +x setup_pi.sh && ./setup_pi.sh
nano .env   # Configure API keys
python3 main.py
```

### Bluetooth Audio (Wireless Headset)

```bash
./setup_bluetooth.sh
```

---

## ğŸ”‘ API Configuration

### Environment Variables

```env
# Required
OPENAI_API_KEY=sk-...          # GPT-5-nano access

# Optional (enables additional features)
PICOVOICE_ACCESS_KEY=...       # "Jarvis" wake word
WEATHER_API_KEY=...            # Weather queries
NEWS_API_KEY=...               # News headlines
```

### API Endpoints Used

| Service | Endpoint | Purpose |
|---------|----------|---------|
| OpenAI | `api.openai.com/v1/responses` | LLM inference |
| Google STT | `speech.googleapis.com` | Speech recognition |
| Picovoice | On-device | Wake word detection |
| OpenWeatherMap | `api.openweathermap.org` | Weather data |
| NewsAPI | `newsapi.org` | News aggregation |

---

## ğŸ“ Module Reference

```
Iveri-AI-/
â”œâ”€â”€ main.py              # Entry point, mode routing, conversation loop
â”œâ”€â”€ speech.py            # Microphone capture, Google STT integration
â”œâ”€â”€ tts.py               # Text-to-speech engine, voice synthesis
â”œâ”€â”€ gpt.py               # OpenAI GPT-5-nano API wrapper
â”œâ”€â”€ wakeword.py          # Porcupine wake word detection
â”œâ”€â”€ commands.py          # Intent classifier, 59 command handlers
â”œâ”€â”€ memory.py            # Persistent key-value store, notes system
â”œâ”€â”€ internet_tasks.py    # Weather API, News API integration
â”œâ”€â”€ hardware.py          # GPIO abstraction, LED control
â”œâ”€â”€ config.py            # Centralized configuration management
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ setup_pi.sh          # Automated Raspberry Pi setup
â”œâ”€â”€ setup_bluetooth.sh   # Bluetooth audio pairing script
â”œâ”€â”€ iveri.service        # Systemd service for auto-start
â””â”€â”€ data/
    â”œâ”€â”€ memory.json      # User memory persistence
    â””â”€â”€ notes.json       # Notes storage
```

---

## ğŸ”¬ Research Applications

IVERI provides a platform for research in:

| Domain | Application |
|--------|-------------|
| **Human-Computer Interaction** | Natural language interface studies |
| **Accessibility** | Voice computing for visually impaired users |
| **Edge AI** | On-device NLP without cloud dependency |
| **Smart Environments** | Voice-controlled lab equipment via GPIO |
| **Ubiquitous Computing** | Ambient intelligence systems |
| **Conversational AI** | Multi-turn dialogue management |

### Extensibility

```python
# Adding custom commands (commands.py)
if 'run experiment' in text:
    gpio.trigger_sensor()
    return True, "Experiment started."

# Adding new intents (memory.py)
if 'set alarm' in text:
    time = extract_time(text)
    scheduler.add(time, alarm_callback)
    return True, f"Alarm set for {time}."
```

---

## ğŸš€ Deployment

### Auto-Start on Boot (Systemd)

```bash
sudo systemctl enable iveri
sudo systemctl start iveri
sudo systemctl status iveri   # Check status
journalctl -u iveri -f        # View logs
```

### Hardware Wiring (LED Control)

```
Raspberry Pi GPIO
    â”‚
    â”œâ”€â”€ GPIO 17 (Pin 11) â”€â”€â”¬â”€â”€ 330Î© â”€â”€ LED (+)
    â”‚                      â”‚
    â””â”€â”€ GND (Pin 6) â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€ LED (-)
```

---

## ğŸ§ª Testing

```bash
python test_complete.py    # Full 59-feature test suite
python test_system.py      # System diagnostics
python test_quick.py       # Quick validation
```

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/NewCapability`)
3. Commit changes (`git commit -m 'Add new capability'`)
4. Push to branch (`git push origin feature/NewCapability`)
5. Open Pull Request

---

## ğŸ“œ License

MIT License - See [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- [OpenAI](https://openai.com) â€” GPT-5-nano language model
- [Picovoice](https://picovoice.ai) â€” On-device wake word engine
- [Google Cloud](https://cloud.google.com/speech-to-text) â€” Speech recognition
- [Raspberry Pi Foundation](https://raspberrypi.org) â€” Edge computing platform

---

<div align="center">

**Built for the future of conversational computing**

â­ Star this repository if you find it useful!

*Research inquiries welcome*

</div>
